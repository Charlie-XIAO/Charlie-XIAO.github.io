---
layout: page
title: Advanced Computer Networks
description: COMPSCI 2430
importance: 1
category: Computational Science (Harvard)
pretty_table: true
toc:
  beginning: true

shortcuts:
  - name: Project
    icon: fa-solid fa-link
    link: /projects/sparse-vllm

course_information:
  Instructor: <a href="https://minlanyu.seas.harvard.edu/">Minlan Yu</a>.
  Semester: Fall 2024.
  Website: <a href="https://github.com/minlanyu/cs243-site/tree/fall2024">https://github.com/minlanyu/cs243-site/tree/fall2024</a>
  Outline: >
    Data parallelism and sharding, model parallelism and pipelining, parameter server and all-reduce, collective communication optimizations;
    LLM training, LLM serving, throughput-latency tradeoffs, distributed serving;
    NCCL as a service, flow scheduling, RDMA, congestion control, ethics;
    Checkpointing, fault tolerance, diagnosis;
    Data ingestion, LLM training in production, TPU, sustainable AI.
  Technologies: Python, C++/CUDA, PyTorch, vLLM, Amazon Web Services (AWS).
---

{% include educations/course_information.md %}

## Project

Our final project was about integration of KV cache sparsification in vLLM in a performant and memory-efficient way. Details of the project can be found [here](/projects/sparse-vllm).
